{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2486696",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exercise Image-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5d5148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.010939Z",
     "start_time": "2023-04-26T16:47:37.006064Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import paths\n",
    "from datasets import VOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "591da245-9ab5-43cc-8df2-17a5c31cd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Image Captioning\n",
    "# Your first task will be to complete the inference code to generate captions for the given VOC dataset.\n",
    "from eval_captioning import extract_evaluate_write_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3ce6b3-fd3d-481a-b164-e7731d3d385a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 23:49:43,956 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-06 23:49:47,387 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-06 23:49:49,061 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-06 23:49:49,115 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-06 23:49:49,714 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-06 23:49:50,307 [INFO] Missing keys []\n",
      "2025-05-06 23:49:50,308 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-06 23:49:50,343 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-06 23:49:50,364 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-06 23:49:50,364 [INFO] Output dir: outputs/eval_captioning/2025_05_06_23_49_50\n",
      "2025-05-06 23:50:02,086 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-06 23:50:02,090 [INFO] Datapoint 0 got output ['a plane on the ground at an airport', 'two trains parked on the tracks', 'a boat in the water near a dock', 'a train at a train station', 'a group of people riding bikes', 'two sheep in the grass together', 'a computer monitor and a keyboard', 'two people sitting on a train', 'a horse standing in the grass', 'a woman holding a bottle of vodka', 'a cat laying on a couch', 'two cows on the beach with the ocean in the background', 'a cow laying down in a pen', 'a cruise ship in the distance', 'a computer monitor and speakers on a desk', 'a bike parked on the side of the road']\n",
      "Captioning images: 100%|██████████| 91/91 [16:02<00:00, 10.58s/it]\n",
      "2025-05-07 00:05:52,958 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_06_23_49_50/pred_captions.txt\n",
      "2025-05-07 00:05:52,959 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_06_23_49_50/ref_captions.txt\n",
      "2025-05-07 00:05:52,960 [INFO] Evaluating captions\n",
      "2025-05-07 00:05:53,138 [INFO] BLEU 1-grams: 0.5678858282540832, 2-grams: 0.4415108475968761, 3-grams: 0.3473413509347541, 4-grams: 0.27953393436609436\n",
      "2025-05-07 00:05:53,139 [INFO] Final BLEU@4: 27.95%\n",
      "2025-05-07 00:05:53,139 [INFO] Scores: {'bleu': 0.27953393436609436}\n",
      "2025-05-07 00:05:53,140 [INFO] Writing scores to outputs/eval_captioning/2025_05_06_23_49_50/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.1 Complete Caption Generation with Greedy Search\n",
    "\n",
    "# TODO: In file models/blip/blip_caption.py complete the methods generate and greedy_search. \n",
    "#       Generate and evaluate captions for the VOC dataset. You should get about 28% BLEU score. (2 points)\n",
    "extract_evaluate_write_captions(use_topk_sampling=False, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1455059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T16:47:37.256254Z",
     "start_time": "2023-04-26T16:47:37.192994Z"
    }
   },
   "outputs": [],
   "source": [
    "voc_path = Path(paths.CV_PATH_VOC)\n",
    "dataset = VOCDataset(voc_path, voc_path / \"ImageSets\" / \"Segmentation\" / \"val.txt\",\n",
    "                     load_captions=True)\n",
    "\n",
    "# load and show generated captions\n",
    "# todo update the path to match your experiment\n",
    "pred_captions_file = \"outputs/eval_captioning/2025_05_05_01_44_01/pred_captions.txt\"\n",
    "with open(pred_captions_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    pred_captions = f.readlines()\n",
    "    \n",
    "from PIL import Image\n",
    "for i in range(10):\n",
    "    data = dataset[i]\n",
    "    display(data[\"image\"])\n",
    "    print(f\"Pred caption: {pred_captions[i]}\")\n",
    "    print(f\"Reference caption: {data['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eceaf88",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:05:53,499 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 00:05:56,879 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 00:05:58,543 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 00:05:58,579 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 00:05:59,221 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 00:05:59,781 [INFO] Missing keys []\n",
      "2025-05-07 00:05:59,782 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 00:05:59,835 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 00:05:59,862 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:05:59,862 [INFO] Output dir: outputs/eval_captioning/2025_05_07_00_05_59\n",
      "2025-05-07 00:06:12,088 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:06:12,090 [INFO] Datapoint 0 got output ['a white airplanes landing gate before landing … others, including a', 'two trains that are sitting next to each other piers on a track', 'a boat tied up to a pier others boats are sitting on the', 'a old train on some trackspwa [ ] with', 'a group of bikers riding down the street9115', 'two sheep lying on top of each other in the grass celestial', 'a computer monitor sitting on a desk and a tv at the', 'two people on a subway looking at the camerashore guaranteen', 'a horse standing under a tent his ladder out side — i', 'me with my vodka bottle in my lap 歌 from @', 'a cat laying on the back of a chair with the door open', 'a cow on a beach with the sea in the background suburban port', 'dairy cows eating hay and hay bales null youtubeeke', 'a cruise ship on the watershore from drivingfarellore', 'a keyboard, monitor, headphones and keyboard regard to a room', \"bicycle parked for someone's bicycle ride at nightbardes\"]\n",
      "Captioning images: 100%|██████████| 91/91 [19:25<00:00, 12.81s/it]\n",
      "2025-05-07 00:25:25,591 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_05_59/pred_captions.txt\n",
      "2025-05-07 00:25:25,592 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_05_59/ref_captions.txt\n",
      "2025-05-07 00:25:25,593 [INFO] Evaluating captions\n",
      "2025-05-07 00:25:25,663 [INFO] BLEU 1-grams: 0.28879487631469014, 2-grams: 0.17366436244309114, 3-grams: 0.10557696812765222, 4-grams: 0.06556602691354341\n",
      "2025-05-07 00:25:25,664 [INFO] Final BLEU@4: 6.56%\n",
      "2025-05-07 00:25:25,664 [INFO] Scores: {'bleu': 0.06556602691354341}\n",
      "2025-05-07 00:25:25,664 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_00_05_59/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Complete Caption Generation with Sampling\n",
    "# TODO: In file models/blip/blip_caption.py complete the method sampling. \n",
    "#       There, Top-K sampling instead of greedy search is used to select the next token when decoding. \n",
    "#       Evaluate again with Top-K sampling.\n",
    "#       You should get a lower BLEU score of about 7% for temperature τ = 1.0, and about 12% for τ = 0.7. \n",
    "#       Why do the results improve with lower temperature? (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf0f95e-95e1-4eaf-b6c4-387268bfc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:25:25,725 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 00:25:28,879 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 00:25:30,531 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 00:25:30,569 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 00:25:31,229 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 00:25:31,689 [INFO] Missing keys []\n",
      "2025-05-07 00:25:31,690 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 00:25:31,731 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 00:25:31,757 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:25:31,758 [INFO] Output dir: outputs/eval_captioning/2025_05_07_00_25_31\n",
      "2025-05-07 00:25:45,774 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:25:45,788 [INFO] Datapoint 0 got output ['a plane from the air port where it is being towed to the airport', 'two trains that are sitting next to each other piers in front of a', 'a boat in the water next to trees gazetteshore letters of the', 'a train on a track with a train and a person walking on one side', 'a group of cyclists riding on a road an indoor track phones are on', 'two sheep in a field of grass null and two small sheep resting in', 'a computer monitor sitting on a desk and a tv at the end', 'two people on a train talking on their cell phones indonesia nully', 'a horse standing near a slide surfing staten islandicialcoming', 'a woman holding a bottle of wine others are also in the background –', 'a cat laying on the back of a chair itself promise to be a', 'a cow on a beach with the ocean in the background jpg snaps', 'a cow that is laying down facility in a barn georgia', 'a cruise ship on the watershore from a car socio - economic problems', 'a computer with a cat sitting in front of it mean threshold an', \"a bike out at night with a street sign till it's gone\"]\n",
      "Captioning images: 100%|██████████| 91/91 [17:08<00:00, 11.30s/it]\n",
      "2025-05-07 00:42:40,028 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_25_31/pred_captions.txt\n",
      "2025-05-07 00:42:40,029 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_25_31/ref_captions.txt\n",
      "2025-05-07 00:42:40,030 [INFO] Evaluating captions\n",
      "2025-05-07 00:42:40,082 [INFO] BLEU 1-grams: 0.39505165851003293, 2-grams: 0.26875832847165876, 3-grams: 0.18484558098768233, 4-grams: 0.12903791199733522\n",
      "2025-05-07 00:42:40,082 [INFO] Final BLEU@4: 12.90%\n",
      "2025-05-07 00:42:40,083 [INFO] Scores: {'bleu': 0.12903791199733522}\n",
      "2025-05-07 00:42:40,083 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_00_25_31/scores.json\n"
     ]
    }
   ],
   "source": [
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4abaff-6d80-43dc-9e2f-4377b09548b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:42:40,145 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 00:42:43,515 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 00:42:45,178 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 00:42:45,218 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 00:42:45,834 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 00:42:46,211 [INFO] Missing keys []\n",
      "2025-05-07 00:42:46,212 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 00:42:46,248 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 00:42:46,269 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:42:46,269 [INFO] Output dir: outputs/eval_captioning/2025_05_07_00_42_46\n",
      "2025-05-07 00:43:00,310 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:43:00,318 [INFO] Datapoint 0 got output ['a plane from the air port where it is being towed to the airport', 'two trains that are sitting next to each other piers in front of a', 'a boat in the water next to trees gazetteshore letters of the', 'a train on a track with a train and a person walking on one side', 'a group of cyclists riding on a road an indoor track phones are on', 'two sheep in a field of grass null and two small sheep resting in', 'a computer monitor sitting on a desk and a tv at the end', 'two people on a train talking on their cell phones indonesia nully', 'a horse standing near a slide surfing staten islandicialcoming', 'a woman holding a bottle of wine others are also in the background –', 'a cat laying on the back of a chair itself promise to be a', 'a cow on a beach with the ocean in the background jpg snaps', 'a cow that is laying down facility in a barn georgia', 'a cruise ship on the watershore from a car socio - economic problems', 'a computer with a cat sitting in front of it mean threshold an', \"a bike out at night with a street sign till it's gone\"]\n",
      "Captioning images: 100%|██████████| 91/91 [17:05<00:00, 11.27s/it]\n",
      "2025-05-07 00:59:51,528 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_42_46/pred_captions.txt\n",
      "2025-05-07 00:59:51,529 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_42_46/ref_captions.txt\n",
      "2025-05-07 00:59:51,530 [INFO] Evaluating captions\n",
      "2025-05-07 00:59:51,581 [INFO] BLEU 1-grams: 0.39505165851003293, 2-grams: 0.26875832847165876, 3-grams: 0.18484558098768233, 4-grams: 0.12903791199733522\n",
      "2025-05-07 00:59:51,582 [INFO] Final BLEU@4: 12.90%\n",
      "2025-05-07 00:59:51,582 [INFO] Scores: {'bleu': 0.12903791199733522}\n",
      "2025-05-07 00:59:51,582 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_00_42_46/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Prompt Engineering 1st\n",
    "# TODO: Experiment with different prompts (the default prompt is “a picture of ”). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the prompt and the resulting BLEU score in a table for each setting. \n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4865af48-a3a1-4ded-b0d5-e97fdd8c6d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:59:51,632 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 00:59:54,990 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 00:59:56,659 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 00:59:56,700 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 00:59:57,367 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 00:59:57,890 [INFO] Missing keys []\n",
      "2025-05-07 00:59:57,891 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 00:59:57,931 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 00:59:57,953 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 00:59:57,953 [INFO] Output dir: outputs/eval_captioning/2025_05_07_00_59_57\n",
      "2025-05-07 01:00:08,842 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:00:08,858 [INFO] Datapoint 0 got output ['plane in the airport hangar that has a passenger boarding area', 'train car on a train track twins and one has', 'picture of a boat on the waterpw —', 'train crossing the tracks near a platformicial [', 'picture of a group of people riding bicycles9 an', 'sheep with a tail of two sheep in the grass', 'computer monitor and keyboard and a monitor, and a laptop', 'photo of me and my friends on the metro an', 'horse standing in the grass under a wooden structure,', 'glass bottle with a red heart in it malaga, spain', 'living room with a couch, chair, and tv geographic', \"cow on the beach eating something, it's a\", 'cow laying in the hay with a cow behind it …', 'view of a cruise ship from a backseat of a car', 'computer monitor, speakers, and mouse celestial null', 'black bike locked to the pole promise to be a bike']\n",
      "Captioning images: 100%|██████████| 91/91 [17:43<00:00, 11.69s/it]\n",
      "2025-05-07 01:17:41,704 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_59_57/pred_captions.txt\n",
      "2025-05-07 01:17:41,705 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_00_59_57/ref_captions.txt\n",
      "2025-05-07 01:17:41,707 [INFO] Evaluating captions\n",
      "2025-05-07 01:17:41,770 [INFO] BLEU 1-grams: 0.32970865818627204, 2-grams: 0.20414086420305308, 3-grams: 0.13505347840729315, 4-grams: 0.0909169981664471\n",
      "2025-05-07 01:17:41,771 [INFO] Final BLEU@4: 9.09%\n",
      "2025-05-07 01:17:41,771 [INFO] Scores: {'bleu': 0.0909169981664471}\n",
      "2025-05-07 01:17:41,771 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_00_59_57/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Prompt Engineering 2nd\n",
    "# TODO: Experiment with different prompts (the default prompt is “a picture of ”). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the prompt and the resulting BLEU score in a table for each setting. \n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"This is a \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91776667-2a52-4abc-a216-b0a38697896c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 01:17:41,840 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 01:17:45,114 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 01:17:46,772 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 01:17:46,810 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 01:17:47,408 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 01:17:47,982 [INFO] Missing keys []\n",
      "2025-05-07 01:17:47,984 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 01:17:48,027 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 01:17:48,048 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:17:48,048 [INFO] Output dir: outputs/eval_captioning/2025_05_07_01_17_48\n",
      "2025-05-07 01:18:01,859 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:18:01,860 [INFO] Datapoint 0 got output [' jet being loaded for flight slave tilling device backwards', 'wo trains parked next to each other others in the photo the same train', ' boat in the water next to a dock establishment opener script', ' train on the tracks near a platformshore lonely, in black', ' group of cyclists riding on a track guaranteeing successeker,', 'wo sheep in a meadow together openerpwe collector, not', ' computer with blue paint on it and a gaming systemicial on', 'wo people in a room looking at the camera on their cell phones indonesia', ' horse standing near a slidepwear and a horse is standing in', ' woman holding a bottle of vodka sporting a smile – not sure what', ' living room with two couches celestials script sporting a cat', ' cow and her baby on the beach - - - - - - -', ' cow lying down on hay motion in a barn georgia', ' cruise ship sailing on the water as a traffic light is next to it', ' computer with a pair of hands on it slave – the computer monitor', \" bike tied to the side of the street dismissing the word'no -\"]\n",
      "Captioning images: 100%|██████████| 91/91 [18:31<00:00, 12.21s/it]\n",
      "2025-05-07 01:36:19,595 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_17_48/pred_captions.txt\n",
      "2025-05-07 01:36:19,596 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_17_48/ref_captions.txt\n",
      "2025-05-07 01:36:19,597 [INFO] Evaluating captions\n",
      "2025-05-07 01:36:19,660 [INFO] BLEU 1-grams: 0.3293838862559005, 2-grams: 0.2090866254219289, 3-grams: 0.14145489706152195, 4-grams: 0.09686960145638417\n",
      "2025-05-07 01:36:19,661 [INFO] Final BLEU@4: 9.69%\n",
      "2025-05-07 01:36:19,661 [INFO] Scores: {'bleu': 0.09686960145638417}\n",
      "2025-05-07 01:36:19,661 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_01_17_48/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Prompt Engineering 3rd\n",
    "# TODO: Experiment with different prompts (the default prompt is “a picture of ”). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the prompt and the resulting BLEU score in a table for each setting. \n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"This image depicts  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a352c828-0517-482d-a607-278accb7c559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 01:36:19,720 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 01:36:23,054 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 01:36:24,707 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 01:36:24,746 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 01:36:25,261 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 01:36:25,850 [INFO] Missing keys []\n",
      "2025-05-07 01:36:25,852 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 01:36:25,891 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 01:36:25,914 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:36:25,915 [INFO] Output dir: outputs/eval_captioning/2025_05_07_01_36_25\n",
      "2025-05-07 01:36:39,546 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:36:39,548 [INFO] Datapoint 0 got output ['a plane from the air port where it is being towed to the airport', 'two trains that are sitting next to each other piers in front of a', 'a boat in the water next to trees gazetteshore letters of the', 'a train on a track with a train and a person walking on one side', 'a group of cyclists riding on a road an indoor track phones are on', 'two sheep in a field of grass null and two small sheep resting in', 'a computer monitor sitting on a desk and a tv at the end', 'two people on a train talking on their cell phones indonesia nully', 'a horse standing near a slide surfing staten islandicialcoming', 'a woman holding a bottle of wine others are also in the background –', 'a cat laying on the back of a chair itself promise to be a', 'a cow on a beach with the ocean in the background jpg snaps', 'a cow that is laying down facility in a barn georgia', 'a cruise ship on the watershore from a car socio - economic problems', 'a computer with a cat sitting in front of it mean threshold an', \"a bike out at night with a street sign till it's gone\"]\n",
      "Captioning images: 100%|██████████| 91/91 [16:59<00:00, 11.21s/it]\n",
      "2025-05-07 01:53:25,642 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_36_25/pred_captions.txt\n",
      "2025-05-07 01:53:25,643 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_36_25/ref_captions.txt\n",
      "2025-05-07 01:53:25,645 [INFO] Evaluating captions\n",
      "2025-05-07 01:53:25,708 [INFO] BLEU 1-grams: 0.39505165851003293, 2-grams: 0.26875832847165876, 3-grams: 0.18484558098768233, 4-grams: 0.12903791199733522\n",
      "2025-05-07 01:53:25,709 [INFO] Final BLEU@4: 12.90%\n",
      "2025-05-07 01:53:25,709 [INFO] Scores: {'bleu': 0.12903791199733522}\n",
      "2025-05-07 01:53:25,709 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_01_36_25/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 1st\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82031ab9-fdef-4ed7-91e2-b06c0da96dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 01:53:25,794 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 01:53:28,967 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 01:53:30,614 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 01:53:30,839 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 01:53:31,527 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 01:53:31,973 [INFO] Missing keys []\n",
      "2025-05-07 01:53:31,974 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 01:53:32,017 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 01:53:32,042 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:53:32,043 [INFO] Output dir: outputs/eval_captioning/2025_05_07_01_53_32\n",
      "2025-05-07 01:53:44,899 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 01:53:44,900 [INFO] Datapoint 0 got output ['a white airplanes landing gate before landing … others, including a', 'two trains that are sitting next to each other piers on a track', 'a boat tied up to a pier others boats are sitting on the', 'a old train on some trackspwa [ ] with', 'a group of bikers riding down the street9115', 'two sheep lying on top of each other in the grass celestial', 'a computer monitor sitting on a desk and a tv at the', 'two people on a subway looking at the camerashore guaranteen', 'a horse standing under a tent his ladder out side — i', 'me with my vodka bottle in my lap 歌 from @', 'a cat laying on the back of a chair with the door open', 'a cow on a beach with the sea in the background suburban port', 'dairy cows eating hay and hay bales null youtubeeke', 'a cruise ship on the watershore from drivingfarellore', 'a keyboard, monitor, headphones and keyboard regard to a room', \"bicycle parked for someone's bicycle ride at nightbardes\"]\n",
      "Captioning images: 100%|██████████| 91/91 [19:23<00:00, 12.79s/it]\n",
      "2025-05-07 02:12:55,929 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_53_32/pred_captions.txt\n",
      "2025-05-07 02:12:55,930 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_01_53_32/ref_captions.txt\n",
      "2025-05-07 02:12:55,931 [INFO] Evaluating captions\n",
      "2025-05-07 02:12:55,989 [INFO] BLEU 1-grams: 0.28879487631469014, 2-grams: 0.17366436244309114, 3-grams: 0.10557696812765222, 4-grams: 0.06556602691354341\n",
      "2025-05-07 02:12:55,989 [INFO] Final BLEU@4: 6.56%\n",
      "2025-05-07 02:12:55,990 [INFO] Scores: {'bleu': 0.06556602691354341}\n",
      "2025-05-07 02:12:55,991 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_01_53_32/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 2nd\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=50, temperature=1.0, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19b8375-f324-4938-9fd9-ecd333867fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 02:12:56,053 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 02:12:59,354 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 02:13:01,009 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 02:13:01,047 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 02:13:01,532 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 02:13:02,138 [INFO] Missing keys []\n",
      "2025-05-07 02:13:02,142 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 02:13:02,181 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 02:13:02,207 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:13:02,207 [INFO] Output dir: outputs/eval_captioning/2025_05_07_02_13_02\n",
      "2025-05-07 02:13:15,909 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:13:15,914 [INFO] Datapoint 0 got output ['a plane on a runway with people itself others around,', 'two trains on the tracks near each other with two cars on it', 'a canal with boats in it with a sign in the background with', 'a train going down the track itself in the dark and a', 'a group of people on bikes with one man on the other', 'two sheep laying in the grass a couple of sheep are sitting on it', 'a desk with a computer and other equipment in it and a', 'a man and a woman on the phone on a train', 'a horse standing in a field staten with a slide and', 'me with my vodka, a bottle of vodka and a cup of coffee', 'a room with a couch and table a cat is sleeping on a', 'a horse and its mother on the beach in the ocean - -', 'a cow laying down on a hay a fence and hay', 'a cruise ship from the inside of a car in the street', 'a computer that is on a desk - - a computer monitor', 'a motorcycle parked next to a building scripting a movie the']\n",
      "Captioning images: 100%|██████████| 91/91 [16:58<00:00, 11.19s/it]\n",
      "2025-05-07 02:30:00,870 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_13_02/pred_captions.txt\n",
      "2025-05-07 02:30:00,874 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_13_02/ref_captions.txt\n",
      "2025-05-07 02:30:00,875 [INFO] Evaluating captions\n",
      "2025-05-07 02:30:00,931 [INFO] BLEU 1-grams: 0.40029631625022555, 2-grams: 0.2713606428249738, 3-grams: 0.18484361178947484, 4-grams: 0.128825459575389\n",
      "2025-05-07 02:30:00,931 [INFO] Final BLEU@4: 12.88%\n",
      "2025-05-07 02:30:00,932 [INFO] Scores: {'bleu': 0.128825459575389}\n",
      "2025-05-07 02:30:00,932 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_02_13_02/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 3rd\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=10, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba24349-f129-4562-8dc8-6bf86984119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 02:30:00,989 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 02:30:04,191 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 02:30:05,835 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 02:30:05,878 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 02:30:06,477 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 02:30:06,946 [INFO] Missing keys []\n",
      "2025-05-07 02:30:06,946 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 02:30:06,985 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 02:30:07,010 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:30:07,013 [INFO] Output dir: outputs/eval_captioning/2025_05_07_02_30_07\n",
      "2025-05-07 02:30:17,575 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:30:17,577 [INFO] Datapoint 0 got output ['a plane at the airport waiting to depart the plane', 'two trains parked on the tracks facility guarantee', 'boats docked in the water near trees cups and boats', 'a train that has some graffiti on itgenoa', 'a group of cyclists on the road regardant la', 'two sheep in a field on a sunny day and', 'a small computer room with a television and a tablet', 'two people that are sitting down others are holding their', 'a small horse in the yard with a slide', 'a girl that is holding a bottle of alcohol jp', 'a cat that is sitting on a couch really', 'two cows laying on the sand situng who', 'a cow laying in a pen each day', 'a cruise ship in a harbor workplace scripting', 'two computer speakers and a computer on a desk –', 'a bike leaning against a pole near a street itself']\n",
      "Captioning images: 100%|██████████| 91/91 [17:03<00:00, 11.25s/it]\n",
      "2025-05-07 02:47:10,923 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_30_07/pred_captions.txt\n",
      "2025-05-07 02:47:10,925 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_30_07/ref_captions.txt\n",
      "2025-05-07 02:47:10,926 [INFO] Evaluating captions\n",
      "2025-05-07 02:47:10,981 [INFO] BLEU 1-grams: 0.39092159559832246, 2-grams: 0.2672072318721247, 3-grams: 0.18249353838462015, 4-grams: 0.12675995808609766\n",
      "2025-05-07 02:47:10,981 [INFO] Final BLEU@4: 12.68%\n",
      "2025-05-07 02:47:10,982 [INFO] Scores: {'bleu': 0.12675995808609766}\n",
      "2025-05-07 02:47:10,982 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_02_30_07/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 4th\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=70, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "341c78a9-8425-4961-adfa-186ee15114db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 02:47:11,055 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 02:47:14,388 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 02:47:16,038 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 02:47:16,077 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 02:47:16,784 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 02:47:17,224 [INFO] Missing keys []\n",
      "2025-05-07 02:47:17,224 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 02:47:17,265 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 02:47:17,291 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:47:17,292 [INFO] Output dir: outputs/eval_captioning/2025_05_07_02_47_17\n",
      "2025-05-07 02:47:29,083 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 02:47:29,085 [INFO] Datapoint 0 got output ['a plane sitting at an airport fictional airporthop', 'two trains on a train track, with a metal building in', 'a boat on the water near some housesliders snaps', 'a train going down some tracks fixture deserted with graffiti', 'a group of people riding on bikeskesstenders', 'two sheep laying in the grass letters i & m left on', 'a computer set up on a desk youtube transition from a', 'two people in front of a mirror odd robotic phones', 'a horse that is in a field at a playground jp', 'a woman holding a bottle of vodkascreen shot of her in', 'a living room with a cat on a couch on a couch', 'two animals on the beach togetherinas possible an ocean', 'a cow on a bench in a barn either of the cows', \"a cruise ship in the distance from a driver's seat\", 'a computer desk with a monitor and speakers surfing meander', 'a bike and a motorcycle parked at a bus stop waterway']\n",
      "Captioning images: 100%|██████████| 91/91 [17:22<00:00, 11.46s/it]\n",
      "2025-05-07 03:04:40,256 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_47_17/pred_captions.txt\n",
      "2025-05-07 03:04:40,257 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_02_47_17/ref_captions.txt\n",
      "2025-05-07 03:04:40,258 [INFO] Evaluating captions\n",
      "2025-05-07 03:04:40,310 [INFO] BLEU 1-grams: 0.387490569919732, 2-grams: 0.26500472073348713, 3-grams: 0.1817025944645123, 4-grams: 0.1259284379387938\n",
      "2025-05-07 03:04:40,310 [INFO] Final BLEU@4: 12.59%\n",
      "2025-05-07 03:04:40,311 [INFO] Scores: {'bleu': 0.1259284379387938}\n",
      "2025-05-07 03:04:40,312 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_02_47_17/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 5th\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=100, temperature=0.7, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39631e21-0e6d-4779-a84e-c65a792b2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 03:04:40,361 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 03:04:43,665 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 03:04:45,321 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 03:04:45,360 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 03:04:46,017 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 03:04:46,555 [INFO] Missing keys []\n",
      "2025-05-07 03:04:46,556 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 03:04:46,590 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 03:04:46,611 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:04:46,612 [INFO] Output dir: outputs/eval_captioning/2025_05_07_03_04_46\n",
      "2025-05-07 03:04:59,582 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:04:59,584 [INFO] Datapoint 0 got output ['a cloudy day with a plane at the airport opener sporting a large', 'two trains sitting on the tracks, each with the first car at rear', 'a boat on the water near some housesliders snapshots', 'a train going down some tracks fixture deserted i love it twins', 'a group of people riding on bikeskesstenders com8', 'two sheep laying in the grass letters i f f on it britain', 'a video game system, in four small pieces bays of a living room', 'two photos of two actors taking a selfiegame sporting the same', 'a horse that is in a grassy field on a slide backwards', 'a woman holding a bottle of medicine sporting and fake water bottle', 'a small room with a couple of couches and table behind the couch', 'two animals on the beach togetherinas a the ocean, and a beach', 'a big cow looking directly at the camera during the day the structure', 'a cruise ship in front of the window corresponding tropical scenes scripting', 'a computer desk with a white keyboard and monitors stacks of books something', 'a bike and two blurry images letters are not only suitable arriving']\n",
      "Captioning images: 100%|██████████| 91/91 [20:02<00:00, 13.22s/it]\n",
      "2025-05-07 03:24:49,329 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_03_04_46/pred_captions.txt\n",
      "2025-05-07 03:24:49,331 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_03_04_46/ref_captions.txt\n",
      "2025-05-07 03:24:49,334 [INFO] Evaluating captions\n",
      "2025-05-07 03:24:49,394 [INFO] BLEU 1-grams: 0.2807698997043144, 2-grams: 0.16793267013343996, 3-grams: 0.10262432270576402, 4-grams: 0.0630795983823032\n",
      "2025-05-07 03:24:49,395 [INFO] Final BLEU@4: 6.31%\n",
      "2025-05-07 03:24:49,395 [INFO] Scores: {'bleu': 0.0630795983823032}\n",
      "2025-05-07 03:24:49,396 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_03_04_46/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 6th\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=True, topk=100, temperature=1.0, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8adc7314-2e3c-4daa-9231-0b8cfe8c137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 03:24:49,455 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 03:24:52,827 [INFO] Done initializing weights for BertModel BertModel.\n",
      "2025-05-07 03:24:54,498 [INFO] Done initializing weights for BertModel BertLMHeadModel.\n",
      "2025-05-07 03:24:54,539 [INFO] Created model BlipCaption with 247.4M parameters.\n",
      "2025-05-07 03:24:55,076 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 03:24:55,580 [INFO] Missing keys []\n",
      "2025-05-07 03:24:55,581 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 03:24:55,617 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 03:24:55,640 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:24:55,640 [INFO] Output dir: outputs/eval_captioning/2025_05_07_03_24_55\n",
      "2025-05-07 03:25:06,876 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:25:06,880 [INFO] Datapoint 0 got output ['a plane on the ground at an airport', 'two trains parked on the tracks', 'a boat in the water near a dock', 'a train at a train station', 'a group of people riding bikes', 'two sheep in the grass together', 'a computer monitor and a keyboard', 'two people sitting on a train', 'a horse standing in the grass', 'a woman holding a bottle of vodka', 'a cat laying on a couch', 'two cows on the beach with the ocean in the background', 'a cow laying down in a pen', 'a cruise ship in the distance', 'a computer monitor and speakers on a desk', 'a bike parked on the side of the road']\n",
      "Captioning images: 100%|██████████| 91/91 [16:38<00:00, 10.97s/it]\n",
      "2025-05-07 03:41:34,028 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_03_24_55/pred_captions.txt\n",
      "2025-05-07 03:41:34,031 [INFO] Writing 1449 captions to outputs/eval_captioning/2025_05_07_03_24_55/ref_captions.txt\n",
      "2025-05-07 03:41:34,032 [INFO] Evaluating captions\n",
      "2025-05-07 03:41:34,089 [INFO] BLEU 1-grams: 0.5678858282540832, 2-grams: 0.4415108475968761, 3-grams: 0.3473413509347541, 4-grams: 0.27953393436609436\n",
      "2025-05-07 03:41:34,089 [INFO] Final BLEU@4: 27.95%\n",
      "2025-05-07 03:41:34,090 [INFO] Scores: {'bleu': 0.27953393436609436}\n",
      "2025-05-07 03:41:34,090 [INFO] Writing scores to outputs/eval_captioning/2025_05_07_03_24_55/scores.json\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Student Hyperparameter Search 7th\n",
    "# TODO: Experiment with different decoding parameters. (Top-K with different K and temperature or greedy decoding). \n",
    "#       Can you improve the BLEU score? Try at least 3 new settings.\n",
    "#       Note the hyperparameters, the prompt and the resulting BLEU score in a table for each setting.\n",
    "#       Add the table to your report. (1 point)\n",
    "extract_evaluate_write_captions(use_topk_sampling=False, prompt=\"a picture of \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bf535e-447d-4493-bd4f-e12731007a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c3f0cb7-6677-49ed-be36-1891dae6e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Image-Text Retrieval\n",
    "# Your second task will be to train and evaluate the retrieval head of the BLIP model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44d87144-6833-4d58-ac2b-9bc8f4e69119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 03:41:34,180 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 03:41:37,534 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 03:41:37,577 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 03:41:38,126 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 03:41:38,560 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 03:41:38,560 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 03:41:38,601 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 03:41:38,605 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:41:38,606 [INFO] Output dir: outputs/eval_retrieval/2025_05_07_03_41_38\n",
      "2025-05-07 03:41:38,606 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:47<00:00,  3.16s/it]\n",
      "2025-05-07 03:46:26,689 [INFO] Validation results: {'i_r1': 0.533471359558316, 'i_r5': 0.8067632850241546, 'i_r10': 0.906832298136646, 'i_medr': 1.0, 'i_meanr': 4.0690131124913735, 't_r1': 0.5355417529330573, 't_r5': 0.8184955141476881, 't_r10': 0.8923395445134575, 't_medr': 1.0, 't_meanr': 4.680469289164941}\n",
      "2025-05-07 03:46:26,690 [INFO] Max GPU memory allocated: 0.000M\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Complete Forward Pass and Evaluate\n",
    "#     Todo: Complete the forward pass in file models/blip/blip_retrieval.py. \n",
    "#           Evaluate your implementation with the provided checkpoint. \n",
    "#           You should get about 54% image-to-text R@1. (2 points)\n",
    "from eval_retrieval import eval_without_args \n",
    "eval_without_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8d4778a-aa46-4933-95c0-98b66b697bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 03:46:26,961 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 03:46:29,914 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 03:46:29,950 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 03:46:30,453 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 03:46:30,736 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 03:46:30,736 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 03:46:30,766 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 03:46:30,767 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 03:46:30,767 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 03:46:30,767 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 03:46:30,767 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 03:46:30,804 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:46:30,805 [INFO] Output dir: outputs/train_retrieval/2025_05_07_03_46_30\n",
      "2025-05-07 03:46:30,806 [INFO] Training epoch 0\n",
      "2025-05-07 03:46:33,969 [INFO]   step: 0 loss: 2.775 lr: 1.000e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 03:46:33,970 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:47:03,416 [INFO]   step: 10 loss: 1.252 lr: 9.780e-04\n",
      "2025-05-07 03:47:32,997 [INFO]   step: 20 loss: 0.446 lr: 9.560e-04\n",
      "2025-05-07 03:48:02,684 [INFO]   step: 30 loss: 0.633 lr: 9.341e-04\n",
      "2025-05-07 03:48:32,194 [INFO]   step: 40 loss: 0.524 lr: 9.121e-04\n",
      "2025-05-07 03:49:01,623 [INFO]   step: 50 loss: 0.489 lr: 8.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [02:30<02:00,  2.94s/it]2025-05-07 03:49:01,624 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:49:31,052 [INFO]   step: 60 loss: 0.483 lr: 8.681e-04\n",
      "2025-05-07 03:50:00,454 [INFO]   step: 70 loss: 0.304 lr: 8.462e-04\n",
      "2025-05-07 03:50:30,176 [INFO]   step: 80 loss: 0.172 lr: 8.242e-04\n",
      "2025-05-07 03:50:59,748 [INFO]   step: 90 loss: 0.256 lr: 8.022e-04\n",
      "Training: 100%|██████████| 91/91 [04:28<00:00,  2.95s/it]2025-05-07 03:50:59,750 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:28<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:23<00:00,  2.89s/it]\n",
      "2025-05-07 03:55:23,139 [INFO] Validation results: {'i_r1': 0.3409247757073844, 'i_r5': 0.6818495514147688, 'i_r10': 0.8081435472739821, 'i_medr': 3.0, 'i_meanr': 8.356797791580401, 't_r1': 0.3326432022084196, 't_r5': 0.6466528640441684, 't_r10': 0.7784679089026915, 't_medr': 3.0, 't_meanr': 8.871635610766045}\n",
      "2025-05-07 03:55:23,161 [INFO] Training epoch 1\n",
      "2025-05-07 03:55:26,150 [INFO]   step: 0 loss: 0.121 lr: 8.000e-04\n",
      "Training:   0%|          | 0/91 [00:02<?, ?it/s]2025-05-07 03:55:26,151 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:55:55,733 [INFO]   step: 10 loss: 0.195 lr: 7.780e-04\n",
      "2025-05-07 03:56:25,185 [INFO]   step: 20 loss: 0.377 lr: 7.560e-04\n",
      "2025-05-07 03:56:54,751 [INFO]   step: 30 loss: 0.346 lr: 7.341e-04\n",
      "2025-05-07 03:57:24,356 [INFO]   step: 40 loss: 0.191 lr: 7.121e-04\n",
      "2025-05-07 03:57:53,986 [INFO]   step: 50 loss: 0.292 lr: 6.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [02:30<02:01,  2.96s/it]2025-05-07 03:57:53,988 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 03:58:23,607 [INFO]   step: 60 loss: 0.119 lr: 6.681e-04\n",
      "2025-05-07 03:58:53,333 [INFO]   step: 70 loss: 0.221 lr: 6.462e-04\n",
      "2025-05-07 03:59:22,778 [INFO]   step: 80 loss: 0.104 lr: 6.242e-04\n",
      "2025-05-07 03:59:52,251 [INFO]   step: 90 loss: 0.168 lr: 6.022e-04\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.95s/it]2025-05-07 03:59:52,253 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:23<00:00,  2.89s/it]\n",
      "2025-05-07 04:04:15,684 [INFO] Validation results: {'i_r1': 0.38509316770186336, 'i_r5': 0.6963423050379572, 'i_r10': 0.831608005521049, 'i_medr': 2.0, 'i_meanr': 6.8854382332643205, 't_r1': 0.37681159420289856, 't_r5': 0.6859903381642513, 't_r10': 0.8122843340234644, 't_medr': 2.0, 't_meanr': 7.5272601794340925}\n",
      "2025-05-07 04:04:15,705 [INFO] Training epoch 2\n",
      "2025-05-07 04:04:18,724 [INFO]   step: 0 loss: 0.412 lr: 6.000e-04\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:04:18,726 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:04:48,157 [INFO]   step: 10 loss: 0.054 lr: 5.780e-04\n",
      "2025-05-07 04:05:17,817 [INFO]   step: 20 loss: 0.118 lr: 5.560e-04\n",
      "2025-05-07 04:05:47,801 [INFO]   step: 30 loss: 0.163 lr: 5.341e-04\n",
      "2025-05-07 04:06:17,440 [INFO]   step: 40 loss: 0.086 lr: 5.121e-04\n",
      "2025-05-07 04:06:47,055 [INFO]   step: 50 loss: 0.333 lr: 4.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:01,  2.95s/it]2025-05-07 04:06:47,056 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:07:16,495 [INFO]   step: 60 loss: 0.267 lr: 4.681e-04\n",
      "2025-05-07 04:07:46,044 [INFO]   step: 70 loss: 0.251 lr: 4.462e-04\n",
      "2025-05-07 04:08:15,759 [INFO]   step: 80 loss: 0.152 lr: 4.242e-04\n",
      "2025-05-07 04:08:45,349 [INFO]   step: 90 loss: 0.135 lr: 4.022e-04\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.95s/it]2025-05-07 04:08:45,351 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:22<00:00,  2.89s/it]\n",
      "2025-05-07 04:13:08,330 [INFO] Validation results: {'i_r1': 0.4106280193236715, 'i_r5': 0.7156659765355418, 'i_r10': 0.8474810213940649, 'i_medr': 2.0, 'i_meanr': 6.358178053830228, 't_r1': 0.38716356107660455, 't_r5': 0.7060041407867494, 't_r10': 0.8295376121463078, 't_medr': 2.0, 't_meanr': 6.703243616287095}\n",
      "2025-05-07 04:13:08,366 [INFO] Training epoch 3\n",
      "2025-05-07 04:13:11,369 [INFO]   step: 0 loss: 0.124 lr: 4.000e-04\n",
      "Training:   0%|          | 0/91 [00:02<?, ?it/s]2025-05-07 04:13:11,371 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:13:40,747 [INFO]   step: 10 loss: 0.159 lr: 3.780e-04\n",
      "2025-05-07 04:14:10,323 [INFO]   step: 20 loss: 0.107 lr: 3.560e-04\n",
      "2025-05-07 04:14:39,831 [INFO]   step: 30 loss: 0.244 lr: 3.341e-04\n",
      "2025-05-07 04:15:09,349 [INFO]   step: 40 loss: 0.114 lr: 3.121e-04\n",
      "2025-05-07 04:15:38,917 [INFO]   step: 50 loss: 0.075 lr: 2.901e-04\n",
      "Training:  55%|█████▍    | 50/91 [02:30<02:01,  2.97s/it]2025-05-07 04:15:38,918 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:16:08,442 [INFO]   step: 60 loss: 0.186 lr: 2.681e-04\n",
      "2025-05-07 04:16:38,134 [INFO]   step: 70 loss: 0.114 lr: 2.462e-04\n",
      "2025-05-07 04:17:07,729 [INFO]   step: 80 loss: 0.036 lr: 2.242e-04\n",
      "2025-05-07 04:17:37,126 [INFO]   step: 90 loss: 0.201 lr: 2.022e-04\n",
      "Training: 100%|██████████| 91/91 [04:28<00:00,  2.93s/it]2025-05-07 04:17:37,128 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:28<00:00,  2.95s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:23<00:00,  2.89s/it]\n",
      "2025-05-07 04:22:00,599 [INFO] Validation results: {'i_r1': 0.4416839199447895, 'i_r5': 0.7515527950310559, 'i_r10': 0.8743961352657005, 'i_medr': 2.0, 'i_meanr': 5.670117322291236, 't_r1': 0.4085576259489303, 't_r5': 0.7356797791580401, 't_r10': 0.8474810213940649, 't_medr': 2.0, 't_meanr': 6.341614906832298}\n",
      "2025-05-07 04:22:00,629 [INFO] Training epoch 4\n",
      "2025-05-07 04:22:03,689 [INFO]   step: 0 loss: 0.105 lr: 2.000e-04\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:22:03,690 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:22:33,405 [INFO]   step: 10 loss: 0.154 lr: 1.780e-04\n",
      "2025-05-07 04:23:03,048 [INFO]   step: 20 loss: 0.139 lr: 1.560e-04\n",
      "2025-05-07 04:23:32,896 [INFO]   step: 30 loss: 0.115 lr: 1.341e-04\n",
      "2025-05-07 04:24:02,517 [INFO]   step: 40 loss: 0.062 lr: 1.121e-04\n",
      "2025-05-07 04:24:32,049 [INFO]   step: 50 loss: 0.089 lr: 9.011e-05\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:00,  2.93s/it]2025-05-07 04:24:32,050 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:25:01,684 [INFO]   step: 60 loss: 0.140 lr: 6.813e-05\n",
      "2025-05-07 04:25:31,215 [INFO]   step: 70 loss: 0.113 lr: 4.615e-05\n",
      "2025-05-07 04:26:00,774 [INFO]   step: 80 loss: 0.067 lr: 2.418e-05\n",
      "2025-05-07 04:26:30,223 [INFO]   step: 90 loss: 0.056 lr: 2.198e-06\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.94s/it]2025-05-07 04:26:30,225 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:23<00:00,  2.90s/it]\n",
      "2025-05-07 04:30:54,188 [INFO] Validation results: {'i_r1': 0.45134575569358176, 'i_r5': 0.7577639751552795, 'i_r10': 0.8764665286404417, 'i_medr': 2.0, 'i_meanr': 5.519668737060042, 't_r1': 0.4147688060731539, 't_r5': 0.7336093857832988, 't_r10': 0.855072463768116, 't_medr': 2.0, 't_meanr': 6.203588681849552}\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Complete Loss and Train from Scratch\n",
    "# Todo: Complete the loss computation in file train_retrieval.py function train_epoch. \n",
    "#       Train the retrieval projection layers from scratch (i.e. from random initialization).\n",
    "#       You should get about 43% image-to-text R@1. (1 point)\n",
    "from train_retrieval import train_retrieval_without_args\n",
    "train_retrieval_without_args(finetune=False, learning_rate=1e-3, weight_decay=1e-3, epochs=5, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dadb532e-65e3-4e24-8fa9-2a26e3ea6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 04:30:54,269 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 04:30:57,101 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 04:30:57,139 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 04:30:57,647 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 04:30:57,961 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 04:30:57,961 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 04:30:57,988 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 04:30:57,993 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 04:30:57,993 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 04:30:57,993 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 04:30:57,993 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 04:30:57,994 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 04:30:58,032 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:30:58,034 [INFO] Output dir: outputs/train_retrieval/2025_05_07_04_30_58\n",
      "2025-05-07 04:30:58,035 [INFO] Training epoch 0\n",
      "2025-05-07 04:31:01,117 [INFO]   step: 0 loss: 1.558 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:31:01,118 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:31:30,668 [INFO]   step: 10 loss: 1.609 lr: 9.634e-06\n",
      "2025-05-07 04:32:00,292 [INFO]   step: 20 loss: 1.530 lr: 9.267e-06\n",
      "2025-05-07 04:32:29,890 [INFO]   step: 30 loss: 1.533 lr: 8.901e-06\n",
      "2025-05-07 04:32:59,515 [INFO]   step: 40 loss: 1.570 lr: 8.535e-06\n",
      "2025-05-07 04:33:29,114 [INFO]   step: 50 loss: 1.445 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:00,  2.95s/it]2025-05-07 04:33:29,115 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:33:58,568 [INFO]   step: 60 loss: 1.552 lr: 7.802e-06\n",
      "2025-05-07 04:34:28,213 [INFO]   step: 70 loss: 1.381 lr: 7.436e-06\n",
      "2025-05-07 04:34:57,580 [INFO]   step: 80 loss: 1.435 lr: 7.070e-06\n",
      "2025-05-07 04:35:27,327 [INFO]   step: 90 loss: 1.204 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.97s/it]2025-05-07 04:35:27,328 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 04:39:52,217 [INFO] Validation results: {'i_r1': 0.5866114561766735, 'i_r5': 0.8557625948930296, 'i_r10': 0.9371980676328503, 'i_medr': 1.0, 'i_meanr': 3.2111801242236027, 't_r1': 0.5479641131815045, 't_r5': 0.828847481021394, 't_r10': 0.9013112491373361, 't_medr': 1.0, 't_meanr': 4.474810213940649}\n",
      "2025-05-07 04:39:52,242 [INFO] Training epoch 1\n",
      "2025-05-07 04:39:55,366 [INFO]   step: 0 loss: 1.444 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:39:55,367 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:40:25,296 [INFO]   step: 10 loss: 1.370 lr: 6.300e-06\n",
      "2025-05-07 04:40:55,150 [INFO]   step: 20 loss: 1.235 lr: 5.934e-06\n",
      "2025-05-07 04:41:25,037 [INFO]   step: 30 loss: 1.279 lr: 5.568e-06\n",
      "2025-05-07 04:41:54,504 [INFO]   step: 40 loss: 1.359 lr: 5.201e-06\n",
      "2025-05-07 04:42:24,293 [INFO]   step: 50 loss: 1.453 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:32<02:02,  2.99s/it]2025-05-07 04:42:24,295 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:42:53,911 [INFO]   step: 60 loss: 1.255 lr: 4.469e-06\n",
      "2025-05-07 04:43:23,508 [INFO]   step: 70 loss: 1.287 lr: 4.103e-06\n",
      "2025-05-07 04:43:53,211 [INFO]   step: 80 loss: 1.211 lr: 3.736e-06\n",
      "2025-05-07 04:44:22,861 [INFO]   step: 90 loss: 1.281 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.96s/it]2025-05-07 04:44:22,863 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.97s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.90s/it]\n",
      "2025-05-07 04:48:47,404 [INFO] Validation results: {'i_r1': 0.5921325051759835, 'i_r5': 0.855072463768116, 'i_r10': 0.9385783298826778, 'i_medr': 1.0, 'i_meanr': 3.133885438233264, 't_r1': 0.5548654244306418, 't_r5': 0.8295376121463078, 't_r10': 0.904071773636991, 't_medr': 1.0, 't_meanr': 4.370600414078675}\n",
      "2025-05-07 04:48:47,424 [INFO] Training epoch 2\n",
      "2025-05-07 04:48:50,448 [INFO]   step: 0 loss: 1.266 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:48:50,449 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:49:20,175 [INFO]   step: 10 loss: 1.084 lr: 2.967e-06\n",
      "2025-05-07 04:49:49,845 [INFO]   step: 20 loss: 1.391 lr: 2.601e-06\n",
      "2025-05-07 04:50:19,605 [INFO]   step: 30 loss: 1.245 lr: 2.234e-06\n",
      "2025-05-07 04:50:49,458 [INFO]   step: 40 loss: 1.311 lr: 1.868e-06\n",
      "2025-05-07 04:51:19,188 [INFO]   step: 50 loss: 1.263 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:01,  2.97s/it]2025-05-07 04:51:19,189 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:51:49,083 [INFO]   step: 60 loss: 1.131 lr: 1.136e-06\n",
      "2025-05-07 04:52:18,914 [INFO]   step: 70 loss: 1.271 lr: 7.692e-07\n",
      "2025-05-07 04:52:48,983 [INFO]   step: 80 loss: 1.111 lr: 4.029e-07\n",
      "2025-05-07 04:53:18,691 [INFO]   step: 90 loss: 1.186 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  2.97s/it]2025-05-07 04:53:18,692 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  2.98s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:25<00:00,  2.91s/it]\n",
      "2025-05-07 04:57:44,000 [INFO] Validation results: {'i_r1': 0.5838509316770186, 'i_r5': 0.8530020703933747, 'i_r10': 0.9358178053830227, 'i_medr': 1.0, 'i_meanr': 3.1635610766045548, 't_r1': 0.5521048999309869, 't_r5': 0.8309178743961353, 't_r10': 0.9033816425120773, 't_medr': 1.0, 't_meanr': 4.3436853002070395}\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Finetune instead of Train from Scratch\n",
    "# Todo: Now, try finetuning the head instead with --finetune. \n",
    "#       Set learning rate to 1e-5, weight decay to 0 and train for 3 epochs. \n",
    "#       What score do you get and how can you explain the difference to the score when training from scratch? (1 point)\n",
    "#       Try different search queries. What do you observe?\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=0, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64660e3d-13a2-4fd9-bea9-bd22f32c3524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 04:57:44,101 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 04:57:46,931 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 04:57:46,966 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 04:57:47,483 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 04:57:47,810 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 04:57:47,810 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 04:57:47,840 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 04:57:47,844 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 04:57:47,845 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 04:57:47,845 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 04:57:47,845 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 04:57:47,845 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 04:57:47,884 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:57:47,885 [INFO] Output dir: outputs/train_retrieval/2025_05_07_04_57_47\n",
      "2025-05-07 04:57:47,887 [INFO] Training epoch 0\n",
      "2025-05-07 04:57:50,960 [INFO]   step: 0 loss: 1.589 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 04:57:50,961 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 04:58:20,747 [INFO]   step: 10 loss: 1.594 lr: 9.634e-06\n",
      "2025-05-07 04:58:50,369 [INFO]   step: 20 loss: 1.651 lr: 9.267e-06\n",
      "2025-05-07 04:59:19,894 [INFO]   step: 30 loss: 1.536 lr: 8.901e-06\n",
      "2025-05-07 04:59:49,633 [INFO]   step: 40 loss: 1.587 lr: 8.535e-06\n",
      "2025-05-07 05:00:19,215 [INFO]   step: 50 loss: 1.438 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:00,  2.95s/it]2025-05-07 05:00:19,216 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:00:48,828 [INFO]   step: 60 loss: 1.547 lr: 7.802e-06\n",
      "2025-05-07 05:01:18,272 [INFO]   step: 70 loss: 1.353 lr: 7.436e-06\n",
      "2025-05-07 05:01:47,872 [INFO]   step: 80 loss: 1.427 lr: 7.070e-06\n",
      "2025-05-07 05:02:17,562 [INFO]   step: 90 loss: 1.229 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.97s/it]2025-05-07 05:02:17,563 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.90s/it]\n",
      "2025-05-07 05:06:42,105 [INFO] Validation results: {'i_r1': 0.5886818495514148, 'i_r5': 0.8564527260179434, 'i_r10': 0.9330572808833678, 'i_medr': 1.0, 'i_meanr': 3.198757763975155, 't_r1': 0.5472739820565907, 't_r5': 0.8281573498964804, 't_r10': 0.8999309868875086, 't_medr': 1.0, 't_meanr': 4.481711525189786}\n",
      "2025-05-07 05:06:42,129 [INFO] Training epoch 1\n",
      "2025-05-07 05:06:45,208 [INFO]   step: 0 loss: 1.455 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 05:06:45,209 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:07:15,057 [INFO]   step: 10 loss: 1.368 lr: 6.300e-06\n",
      "2025-05-07 05:07:44,711 [INFO]   step: 20 loss: 1.234 lr: 5.934e-06\n",
      "2025-05-07 05:08:14,557 [INFO]   step: 30 loss: 1.289 lr: 5.568e-06\n",
      "2025-05-07 05:08:44,209 [INFO]   step: 40 loss: 1.313 lr: 5.201e-06\n",
      "2025-05-07 05:09:13,694 [INFO]   step: 50 loss: 1.493 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:01,  2.95s/it]2025-05-07 05:09:13,695 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:09:43,323 [INFO]   step: 60 loss: 1.221 lr: 4.469e-06\n",
      "2025-05-07 05:10:13,041 [INFO]   step: 70 loss: 1.296 lr: 4.103e-06\n",
      "2025-05-07 05:10:42,621 [INFO]   step: 80 loss: 1.190 lr: 3.736e-06\n",
      "2025-05-07 05:11:12,406 [INFO]   step: 90 loss: 1.285 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.98s/it]2025-05-07 05:11:12,408 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.97s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:25<00:00,  2.91s/it]\n",
      "2025-05-07 05:15:37,843 [INFO] Validation results: {'i_r1': 0.5900621118012422, 'i_r5': 0.8543823326432022, 'i_r10': 0.9399585921325052, 'i_medr': 1.0, 'i_meanr': 3.1380262249827466, 't_r1': 0.5555555555555556, 't_r5': 0.8295376121463078, 't_r10': 0.9033816425120773, 't_medr': 1.0, 't_meanr': 4.365079365079366}\n",
      "2025-05-07 05:15:37,856 [INFO] Training epoch 2\n",
      "2025-05-07 05:15:40,920 [INFO]   step: 0 loss: 1.403 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 05:15:40,921 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:16:10,572 [INFO]   step: 10 loss: 1.093 lr: 2.967e-06\n",
      "2025-05-07 05:16:40,391 [INFO]   step: 20 loss: 1.253 lr: 2.601e-06\n",
      "2025-05-07 05:17:10,137 [INFO]   step: 30 loss: 1.249 lr: 2.234e-06\n",
      "2025-05-07 05:17:40,045 [INFO]   step: 40 loss: 1.312 lr: 1.868e-06\n",
      "2025-05-07 05:18:09,808 [INFO]   step: 50 loss: 1.283 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:02,  3.00s/it]2025-05-07 05:18:09,809 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:18:39,524 [INFO]   step: 60 loss: 1.135 lr: 1.136e-06\n",
      "2025-05-07 05:19:09,313 [INFO]   step: 70 loss: 1.271 lr: 7.692e-07\n",
      "2025-05-07 05:19:38,998 [INFO]   step: 80 loss: 1.103 lr: 4.029e-07\n",
      "2025-05-07 05:20:08,749 [INFO]   step: 90 loss: 1.215 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.99s/it]2025-05-07 05:20:08,751 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.98s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 05:24:33,465 [INFO] Validation results: {'i_r1': 0.5948930296756384, 'i_r5': 0.8571428571428571, 'i_r10': 0.935127674258109, 'i_medr': 1.0, 'i_meanr': 3.1449275362318843, 't_r1': 0.5548654244306418, 't_r5': 0.8309178743961353, 't_r10': 0.904071773636991, 't_medr': 1.0, 't_meanr': 4.338164251207729}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search 1st\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=1e-3, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f208af75-4a7f-4e36-adac-16454febe3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 05:24:33,551 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 05:24:36,389 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 05:24:36,425 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 05:24:36,972 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 05:24:37,292 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 05:24:37,292 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 05:24:37,324 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 05:24:37,328 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 05:24:37,329 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 05:24:37,329 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 05:24:37,329 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 05:24:37,330 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 05:24:37,369 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:24:37,370 [INFO] Output dir: outputs/train_retrieval/2025_05_07_05_24_37\n",
      "2025-05-07 05:24:37,372 [INFO] Training epoch 0\n",
      "2025-05-07 05:24:40,509 [INFO]   step: 0 loss: 1.590 lr: 1.000e-05\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 05:24:40,511 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:25:10,250 [INFO]   step: 10 loss: 1.597 lr: 9.634e-06\n",
      "2025-05-07 05:25:39,888 [INFO]   step: 20 loss: 1.534 lr: 9.267e-06\n",
      "2025-05-07 05:26:09,486 [INFO]   step: 30 loss: 1.638 lr: 8.901e-06\n",
      "2025-05-07 05:26:39,034 [INFO]   step: 40 loss: 1.591 lr: 8.535e-06\n",
      "2025-05-07 05:27:08,581 [INFO]   step: 50 loss: 1.474 lr: 8.168e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:00,  2.95s/it]2025-05-07 05:27:08,582 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:27:38,084 [INFO]   step: 60 loss: 1.569 lr: 7.802e-06\n",
      "2025-05-07 05:28:07,766 [INFO]   step: 70 loss: 1.383 lr: 7.436e-06\n",
      "2025-05-07 05:28:37,317 [INFO]   step: 80 loss: 1.419 lr: 7.070e-06\n",
      "2025-05-07 05:29:06,907 [INFO]   step: 90 loss: 1.244 lr: 6.703e-06\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]2025-05-07 05:29:06,909 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:29<00:00,  2.96s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.90s/it]\n",
      "2025-05-07 05:33:31,298 [INFO] Validation results: {'i_r1': 0.583160800552105, 'i_r5': 0.8592132505175983, 'i_r10': 0.9344375431331953, 'i_medr': 1.0, 'i_meanr': 3.20703933747412, 't_r1': 0.5452035886818496, 't_r5': 0.8302277432712215, 't_r10': 0.9013112491373361, 't_medr': 1.0, 't_meanr': 4.481021394064872}\n",
      "2025-05-07 05:33:31,321 [INFO] Training epoch 1\n",
      "2025-05-07 05:33:34,314 [INFO]   step: 0 loss: 1.442 lr: 6.667e-06\n",
      "Training:   0%|          | 0/91 [00:02<?, ?it/s]2025-05-07 05:33:34,315 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:34:04,014 [INFO]   step: 10 loss: 1.374 lr: 6.300e-06\n",
      "2025-05-07 05:34:33,738 [INFO]   step: 20 loss: 1.226 lr: 5.934e-06\n",
      "2025-05-07 05:35:03,513 [INFO]   step: 30 loss: 1.271 lr: 5.568e-06\n",
      "2025-05-07 05:35:33,299 [INFO]   step: 40 loss: 1.355 lr: 5.201e-06\n",
      "2025-05-07 05:36:02,889 [INFO]   step: 50 loss: 1.403 lr: 4.835e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:01,  2.97s/it]2025-05-07 05:36:02,890 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:36:32,585 [INFO]   step: 60 loss: 1.242 lr: 4.469e-06\n",
      "2025-05-07 05:37:02,169 [INFO]   step: 70 loss: 1.280 lr: 4.103e-06\n",
      "2025-05-07 05:37:31,709 [INFO]   step: 80 loss: 1.233 lr: 3.736e-06\n",
      "2025-05-07 05:38:01,436 [INFO]   step: 90 loss: 1.281 lr: 3.370e-06\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.97s/it]2025-05-07 05:38:01,437 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.97s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 05:42:26,173 [INFO] Validation results: {'i_r1': 0.5955831608005521, 'i_r5': 0.8564527260179434, 'i_r10': 0.935127674258109, 'i_medr': 1.0, 'i_meanr': 3.132505175983437, 't_r1': 0.5548654244306418, 't_r5': 0.8295376121463078, 't_r10': 0.904071773636991, 't_medr': 1.0, 't_meanr': 4.3602484472049685}\n",
      "2025-05-07 05:42:26,195 [INFO] Training epoch 2\n",
      "2025-05-07 05:42:29,292 [INFO]   step: 0 loss: 1.260 lr: 3.333e-06\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 05:42:29,293 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:42:59,006 [INFO]   step: 10 loss: 1.079 lr: 2.967e-06\n",
      "2025-05-07 05:43:28,959 [INFO]   step: 20 loss: 1.261 lr: 2.601e-06\n",
      "2025-05-07 05:43:58,812 [INFO]   step: 30 loss: 1.243 lr: 2.234e-06\n",
      "2025-05-07 05:44:28,815 [INFO]   step: 40 loss: 1.325 lr: 1.868e-06\n",
      "2025-05-07 05:44:58,642 [INFO]   step: 50 loss: 1.258 lr: 1.502e-06\n",
      "Training:  55%|█████▍    | 50/91 [02:32<02:01,  2.97s/it]2025-05-07 05:44:58,643 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:45:28,366 [INFO]   step: 60 loss: 1.116 lr: 1.136e-06\n",
      "2025-05-07 05:45:58,197 [INFO]   step: 70 loss: 1.267 lr: 7.692e-07\n",
      "2025-05-07 05:46:28,115 [INFO]   step: 80 loss: 1.130 lr: 4.029e-07\n",
      "2025-05-07 05:46:57,935 [INFO]   step: 90 loss: 1.188 lr: 3.663e-08\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  2.99s/it]2025-05-07 05:46:57,937 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  2.99s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 05:51:22,885 [INFO] Validation results: {'i_r1': 0.5935127674258109, 'i_r5': 0.8557625948930296, 'i_r10': 0.9371980676328503, 'i_medr': 1.0, 'i_meanr': 3.1387163561076603, 't_r1': 0.5541752933057281, 't_r5': 0.831608005521049, 't_r10': 0.9033816425120773, 't_medr': 1.0, 't_meanr': 4.340924775707384}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search 2nd\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-5, weight_decay=0, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3d26c67-0650-4260-8e8c-a7c44ccd59d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 05:51:22,968 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 05:51:25,806 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 05:51:25,842 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 05:51:26,362 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 05:51:26,644 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 05:51:26,645 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 05:51:26,673 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 05:51:26,677 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 05:51:26,677 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 05:51:26,678 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 05:51:26,678 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 05:51:26,678 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 05:51:26,719 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:51:26,720 [INFO] Output dir: outputs/train_retrieval/2025_05_07_05_51_26\n",
      "2025-05-07 05:51:26,721 [INFO] Training epoch 0\n",
      "2025-05-07 05:51:29,799 [INFO]   step: 0 loss: 1.590 lr: 1.000e-02\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 05:51:29,800 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:51:59,676 [INFO]   step: 10 loss: 1.354 lr: 9.634e-03\n",
      "2025-05-07 05:52:29,717 [INFO]   step: 20 loss: 0.556 lr: 9.267e-03\n",
      "2025-05-07 05:52:59,364 [INFO]   step: 30 loss: 0.752 lr: 8.901e-03\n",
      "2025-05-07 05:53:29,267 [INFO]   step: 40 loss: 0.426 lr: 8.535e-03\n",
      "2025-05-07 05:53:58,979 [INFO]   step: 50 loss: 0.185 lr: 8.168e-03\n",
      "Training:  55%|█████▍    | 50/91 [02:32<02:01,  2.97s/it]2025-05-07 05:53:58,980 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 05:54:28,839 [INFO]   step: 60 loss: 0.764 lr: 7.802e-03\n",
      "2025-05-07 05:54:58,751 [INFO]   step: 70 loss: 0.326 lr: 7.436e-03\n",
      "2025-05-07 05:55:28,644 [INFO]   step: 80 loss: 0.168 lr: 7.070e-03\n",
      "2025-05-07 05:55:58,661 [INFO]   step: 90 loss: 0.242 lr: 6.703e-03\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  3.01s/it]2025-05-07 05:55:58,663 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:31<00:00,  2.99s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:25<00:00,  2.92s/it]\n",
      "2025-05-07 06:00:24,847 [INFO] Validation results: {'i_r1': 0.2691511387163561, 'i_r5': 0.5728088336783989, 'i_r10': 0.7370600414078675, 'i_medr': 4.0, 'i_meanr': 11.394064872325742, 't_r1': 0.28433402346445824, 't_r5': 0.5893719806763285, 't_r10': 0.7198067632850241, 't_medr': 4.0, 't_meanr': 11.380262249827467}\n",
      "2025-05-07 06:00:24,881 [INFO] Training epoch 1\n",
      "2025-05-07 06:00:27,925 [INFO]   step: 0 loss: 0.229 lr: 6.667e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:00:27,927 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:00:57,890 [INFO]   step: 10 loss: 0.231 lr: 6.300e-03\n",
      "2025-05-07 06:01:27,774 [INFO]   step: 20 loss: 0.269 lr: 5.934e-03\n",
      "2025-05-07 06:01:57,514 [INFO]   step: 30 loss: 0.370 lr: 5.568e-03\n",
      "2025-05-07 06:02:27,458 [INFO]   step: 40 loss: 0.117 lr: 5.201e-03\n",
      "2025-05-07 06:02:57,370 [INFO]   step: 50 loss: 0.277 lr: 4.835e-03\n",
      "Training:  55%|█████▍    | 50/91 [02:32<02:03,  3.00s/it]2025-05-07 06:02:57,371 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:03:27,110 [INFO]   step: 60 loss: 0.117 lr: 4.469e-03\n",
      "2025-05-07 06:03:57,027 [INFO]   step: 70 loss: 0.250 lr: 4.103e-03\n",
      "2025-05-07 06:04:27,000 [INFO]   step: 80 loss: 0.131 lr: 3.736e-03\n",
      "2025-05-07 06:04:56,974 [INFO]   step: 90 loss: 0.156 lr: 3.370e-03\n",
      "Training: 100%|██████████| 91/91 [04:32<00:00,  3.02s/it]2025-05-07 06:04:56,975 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:32<00:00,  2.99s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:57<00:00,  3.27s/it]\n",
      "2025-05-07 06:09:55,212 [INFO] Validation results: {'i_r1': 0.32298136645962733, 'i_r5': 0.6466528640441684, 'i_r10': 0.7943409247757074, 'i_medr': 3.0, 'i_meanr': 8.349896480331264, 't_r1': 0.3222912353347136, 't_r5': 0.629399585921325, 't_r10': 0.7646652864044169, 't_medr': 3.0, 't_meanr': 9.161490683229813}\n",
      "2025-05-07 06:09:55,240 [INFO] Training epoch 2\n",
      "2025-05-07 06:09:58,928 [INFO]   step: 0 loss: 0.509 lr: 3.333e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:09:58,929 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:10:35,642 [INFO]   step: 10 loss: 0.063 lr: 2.967e-03\n",
      "2025-05-07 06:11:12,426 [INFO]   step: 20 loss: 0.103 lr: 2.601e-03\n",
      "2025-05-07 06:11:49,386 [INFO]   step: 30 loss: 0.175 lr: 2.234e-03\n",
      "2025-05-07 06:12:26,364 [INFO]   step: 40 loss: 0.097 lr: 1.868e-03\n",
      "2025-05-07 06:13:03,089 [INFO]   step: 50 loss: 0.334 lr: 1.502e-03\n",
      "Training:  55%|█████▍    | 50/91 [03:07<02:30,  3.67s/it]2025-05-07 06:13:03,091 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:13:39,800 [INFO]   step: 60 loss: 0.110 lr: 1.136e-03\n",
      "2025-05-07 06:14:16,577 [INFO]   step: 70 loss: 0.236 lr: 7.692e-04\n",
      "2025-05-07 06:14:53,198 [INFO]   step: 80 loss: 0.421 lr: 4.029e-04\n",
      "2025-05-07 06:15:30,024 [INFO]   step: 90 loss: 0.485 lr: 3.663e-05\n",
      "Training: 100%|██████████| 91/91 [05:34<00:00,  3.68s/it]2025-05-07 06:15:30,026 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [05:34<00:00,  3.68s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [05:27<00:00,  3.60s/it]\n",
      "2025-05-07 06:20:57,481 [INFO] Validation results: {'i_r1': 0.37681159420289856, 'i_r5': 0.6763285024154589, 'i_r10': 0.8281573498964804, 'i_medr': 2.0, 'i_meanr': 7.31608005521049, 't_r1': 0.35955831608005523, 't_r5': 0.663216011042098, 't_r10': 0.7964113181504486, 't_medr': 3.0, 't_meanr': 8.153899240855763}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search 3rd\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-2, weight_decay=1e-3, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e582281-bcb3-4c9d-a665-533cf52e4617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 06:20:57,600 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 06:21:01,596 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 06:21:01,646 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 06:21:02,543 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 06:21:02,995 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 06:21:02,996 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 06:21:03,034 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 06:21:03,041 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 06:21:03,042 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 06:21:03,042 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 06:21:03,042 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 06:21:03,043 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 06:21:03,098 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:21:03,100 [INFO] Output dir: outputs/train_retrieval/2025_05_07_06_21_03\n",
      "2025-05-07 06:21:03,102 [INFO] Training epoch 0\n",
      "2025-05-07 06:21:06,929 [INFO]   step: 0 loss: 1.590 lr: 1.000e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:21:06,931 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:21:43,784 [INFO]   step: 10 loss: 0.534 lr: 9.634e-04\n",
      "2025-05-07 06:22:20,625 [INFO]   step: 20 loss: 0.299 lr: 9.267e-04\n",
      "2025-05-07 06:22:57,347 [INFO]   step: 30 loss: 0.339 lr: 8.901e-04\n",
      "2025-05-07 06:23:34,666 [INFO]   step: 40 loss: 0.322 lr: 8.535e-04\n",
      "2025-05-07 06:24:11,685 [INFO]   step: 50 loss: 0.148 lr: 8.168e-04\n",
      "Training:  55%|█████▍    | 50/91 [03:08<02:32,  3.71s/it]2025-05-07 06:24:11,686 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:24:48,735 [INFO]   step: 60 loss: 0.396 lr: 7.802e-04\n",
      "2025-05-07 06:25:25,818 [INFO]   step: 70 loss: 0.195 lr: 7.436e-04\n",
      "2025-05-07 06:26:02,633 [INFO]   step: 80 loss: 0.125 lr: 7.070e-04\n",
      "2025-05-07 06:26:39,621 [INFO]   step: 90 loss: 0.116 lr: 6.703e-04\n",
      "Training: 100%|██████████| 91/91 [05:36<00:00,  3.68s/it]2025-05-07 06:26:39,624 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [05:36<00:00,  3.70s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [05:26<00:00,  3.58s/it]\n",
      "2025-05-07 06:32:06,047 [INFO] Validation results: {'i_r1': 0.5244996549344375, 'i_r5': 0.8157349896480331, 'i_r10': 0.9102829537612146, 'i_medr': 1.0, 'i_meanr': 4.136645962732919, 't_r1': 0.4968944099378882, 't_r5': 0.7812284334023465, 't_r10': 0.8826777087646653, 't_medr': 2.0, 't_meanr': 5.255348516218081}\n",
      "2025-05-07 06:32:06,069 [INFO] Training epoch 1\n",
      "2025-05-07 06:32:09,875 [INFO]   step: 0 loss: 0.128 lr: 6.667e-04\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:32:09,876 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:32:46,781 [INFO]   step: 10 loss: 0.163 lr: 6.300e-04\n",
      "2025-05-07 06:33:23,610 [INFO]   step: 20 loss: 0.132 lr: 5.934e-04\n",
      "2025-05-07 06:34:00,399 [INFO]   step: 30 loss: 0.217 lr: 5.568e-04\n",
      "2025-05-07 06:34:37,332 [INFO]   step: 40 loss: 0.137 lr: 5.201e-04\n",
      "2025-05-07 06:35:14,171 [INFO]   step: 50 loss: 0.279 lr: 4.835e-04\n",
      "Training:  55%|█████▍    | 50/91 [03:08<02:31,  3.68s/it]2025-05-07 06:35:14,172 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:35:50,973 [INFO]   step: 60 loss: 0.081 lr: 4.469e-04\n",
      "2025-05-07 06:36:27,723 [INFO]   step: 70 loss: 0.158 lr: 4.103e-04\n",
      "2025-05-07 06:37:04,505 [INFO]   step: 80 loss: 0.102 lr: 3.736e-04\n",
      "2025-05-07 06:37:41,306 [INFO]   step: 90 loss: 0.107 lr: 3.370e-04\n",
      "Training: 100%|██████████| 91/91 [05:35<00:00,  3.70s/it]2025-05-07 06:37:41,309 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [05:35<00:00,  3.68s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [05:25<00:00,  3.58s/it]\n",
      "2025-05-07 06:43:07,058 [INFO] Validation results: {'i_r1': 0.5479641131815045, 'i_r5': 0.8309178743961353, 'i_r10': 0.9213250517598344, 'i_medr': 1.0, 'i_meanr': 3.8102139406487234, 't_r1': 0.5106970324361628, 't_r5': 0.7971014492753623, 't_r10': 0.8964803312629399, 't_medr': 1.0, 't_meanr': 4.6977225672877845}\n",
      "2025-05-07 06:43:07,086 [INFO] Training epoch 2\n",
      "2025-05-07 06:43:10,179 [INFO]   step: 0 loss: 0.333 lr: 3.333e-04\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:43:10,181 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:43:42,207 [INFO]   step: 10 loss: 0.041 lr: 2.967e-04\n",
      "2025-05-07 06:44:19,007 [INFO]   step: 20 loss: 0.077 lr: 2.601e-04\n",
      "2025-05-07 06:44:56,041 [INFO]   step: 30 loss: 0.135 lr: 2.234e-04\n",
      "2025-05-07 06:45:32,962 [INFO]   step: 40 loss: 0.078 lr: 1.868e-04\n",
      "2025-05-07 06:46:09,954 [INFO]   step: 50 loss: 0.280 lr: 1.502e-04\n",
      "Training:  55%|█████▍    | 50/91 [03:02<02:31,  3.69s/it]2025-05-07 06:46:09,956 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:46:46,975 [INFO]   step: 60 loss: 0.091 lr: 1.136e-04\n",
      "2025-05-07 06:47:23,816 [INFO]   step: 70 loss: 0.175 lr: 7.692e-05\n",
      "2025-05-07 06:48:00,783 [INFO]   step: 80 loss: 0.137 lr: 4.029e-05\n",
      "2025-05-07 06:48:38,190 [INFO]   step: 90 loss: 0.391 lr: 3.663e-06\n",
      "Training: 100%|██████████| 91/91 [05:31<00:00,  3.72s/it]2025-05-07 06:48:38,193 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [05:31<00:00,  3.64s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [05:27<00:00,  3.60s/it]\n",
      "2025-05-07 06:54:06,442 [INFO] Validation results: {'i_r1': 0.5541752933057281, 'i_r5': 0.8454106280193237, 'i_r10': 0.917184265010352, 'i_medr': 1.0, 'i_meanr': 3.6977225672877845, 't_r1': 0.5086266390614217, 't_r5': 0.8026224982746721, 't_r10': 0.9013112491373361, 't_medr': 1.0, 't_meanr': 4.62663906142167}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search 4th\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-3, weight_decay=1e-2, epochs=3, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebdafcdb-634d-4b4a-99d6-32f41601ff6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 06:54:06,534 [INFO] Running on device: cpu, cuda available: False\n",
      "2025-05-07 06:54:10,508 [INFO] Done initializing weights for BertModel XBertEncoder.\n",
      "2025-05-07 06:54:10,558 [INFO] Created model BlipRetrieval with 223.7M parameters.\n",
      "2025-05-07 06:54:11,424 [INFO] Reshaped position embedding from 196 to 576\n",
      "2025-05-07 06:54:11,888 [INFO] Missing keys ['vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias']\n",
      "2025-05-07 06:54:11,889 [INFO] Done loading checkpoint from ckpt/blip_model_base.pth\n",
      "2025-05-07 06:54:11,928 [INFO] Done loading retrieval head from ckpt/blip_model_retrieval_head.pth\n",
      "2025-05-07 06:54:11,933 [INFO] Will train vision_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 06:54:11,934 [INFO] Will train vision_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 06:54:11,934 [INFO] Will train text_proj.weight with shape torch.Size([256, 768])\n",
      "2025-05-07 06:54:11,934 [INFO] Will train text_proj.bias with shape torch.Size([256])\n",
      "2025-05-07 06:54:11,935 [INFO] Load dataset from data/VOCdevkit/VOC2012\n",
      "2025-05-07 06:54:11,989 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:54:11,990 [INFO] Output dir: outputs/train_retrieval/2025_05_07_06_54_11\n",
      "2025-05-07 06:54:11,992 [INFO] Training epoch 0\n",
      "2025-05-07 06:54:15,861 [INFO]   step: 0 loss: 2.585 lr: 1.000e-02\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 06:54:15,863 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:54:49,584 [INFO]   step: 10 loss: 2.125 lr: 9.634e-03\n",
      "2025-05-07 06:55:19,263 [INFO]   step: 20 loss: 1.848 lr: 9.267e-03\n",
      "2025-05-07 06:55:49,014 [INFO]   step: 30 loss: 1.970 lr: 8.901e-03\n",
      "2025-05-07 06:56:18,896 [INFO]   step: 40 loss: 1.867 lr: 8.535e-03\n",
      "2025-05-07 06:56:48,736 [INFO]   step: 50 loss: 1.775 lr: 8.168e-03\n",
      "Training:  55%|█████▍    | 50/91 [02:36<02:02,  2.98s/it]2025-05-07 06:56:48,737 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 06:57:18,639 [INFO]   step: 60 loss: 1.779 lr: 7.802e-03\n",
      "2025-05-07 06:57:48,228 [INFO]   step: 70 loss: 2.004 lr: 7.436e-03\n",
      "2025-05-07 06:58:18,052 [INFO]   step: 80 loss: 1.808 lr: 7.070e-03\n",
      "2025-05-07 06:58:47,719 [INFO]   step: 90 loss: 1.762 lr: 6.703e-03\n",
      "Training: 100%|██████████| 91/91 [04:35<00:00,  2.95s/it]2025-05-07 06:58:47,722 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:35<00:00,  3.03s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 07:03:12,698 [INFO] Validation results: {'i_r1': 0.19392684610075914, 'i_r5': 0.45686680469289165, 'i_r10': 0.6024844720496895, 'i_medr': 7.0, 'i_meanr': 18.385093167701864, 't_r1': 0.19875776397515527, 't_r5': 0.4527260179434092, 't_r10': 0.6121463077984817, 't_medr': 7.0, 't_meanr': 18.625258799171842}\n",
      "2025-05-07 07:03:12,735 [INFO] Training epoch 1\n",
      "2025-05-07 07:03:15,771 [INFO]   step: 0 loss: 1.819 lr: 6.667e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 07:03:15,773 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 07:03:45,425 [INFO]   step: 10 loss: 1.799 lr: 6.300e-03\n",
      "2025-05-07 07:04:15,234 [INFO]   step: 20 loss: 1.717 lr: 5.934e-03\n",
      "2025-05-07 07:04:44,842 [INFO]   step: 30 loss: 1.803 lr: 5.568e-03\n",
      "2025-05-07 07:05:14,573 [INFO]   step: 40 loss: 1.796 lr: 5.201e-03\n",
      "2025-05-07 07:05:44,326 [INFO]   step: 50 loss: 1.747 lr: 4.835e-03\n",
      "Training:  55%|█████▍    | 50/91 [02:31<02:01,  2.97s/it]2025-05-07 07:05:44,328 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 07:06:14,284 [INFO]   step: 60 loss: 1.749 lr: 4.469e-03\n",
      "2025-05-07 07:06:43,911 [INFO]   step: 70 loss: 1.832 lr: 4.103e-03\n",
      "2025-05-07 07:07:13,585 [INFO]   step: 80 loss: 1.748 lr: 3.736e-03\n",
      "2025-05-07 07:07:43,266 [INFO]   step: 90 loss: 1.762 lr: 3.370e-03\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.95s/it]2025-05-07 07:07:43,268 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:30<00:00,  2.97s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:24<00:00,  2.91s/it]\n",
      "2025-05-07 07:12:08,306 [INFO] Validation results: {'i_r1': 0.22429261559696342, 'i_r5': 0.5175983436853002, 'i_r10': 0.6859903381642513, 'i_medr': 5.0, 'i_meanr': 13.695652173913043, 't_r1': 0.23119392684610077, 't_r5': 0.5086266390614217, 't_r10': 0.6466528640441684, 't_medr': 5.0, 't_meanr': 15.680469289164941}\n",
      "2025-05-07 07:12:08,335 [INFO] Training epoch 2\n",
      "2025-05-07 07:12:11,419 [INFO]   step: 0 loss: 1.786 lr: 3.333e-03\n",
      "Training:   0%|          | 0/91 [00:03<?, ?it/s]2025-05-07 07:12:11,421 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 07:12:40,988 [INFO]   step: 10 loss: 1.701 lr: 2.967e-03\n",
      "2025-05-07 07:13:10,895 [INFO]   step: 20 loss: 1.749 lr: 2.601e-03\n",
      "2025-05-07 07:13:40,568 [INFO]   step: 30 loss: 1.750 lr: 2.234e-03\n",
      "2025-05-07 07:14:11,726 [INFO]   step: 40 loss: 1.749 lr: 1.868e-03\n",
      "2025-05-07 07:14:43,155 [INFO]   step: 50 loss: 1.788 lr: 1.502e-03\n",
      "Training:  55%|█████▍    | 50/91 [02:34<02:12,  3.22s/it]2025-05-07 07:14:43,156 [INFO] GPU/RAM status: CPU‑only — GPU profiler disabled\n",
      "2025-05-07 07:15:13,315 [INFO]   step: 60 loss: 1.720 lr: 1.136e-03\n",
      "2025-05-07 07:15:42,985 [INFO]   step: 70 loss: 1.786 lr: 7.692e-04\n",
      "2025-05-07 07:16:13,602 [INFO]   step: 80 loss: 1.710 lr: 4.029e-04\n",
      "2025-05-07 07:16:43,449 [INFO]   step: 90 loss: 1.780 lr: 3.663e-05\n",
      "Training: 100%|██████████| 91/91 [04:35<00:00,  2.98s/it]2025-05-07 07:16:43,451 [INFO] Max GPU memory allocated: 0.000M\n",
      "Training: 100%|██████████| 91/91 [04:35<00:00,  3.02s/it]\n",
      "Generating retrieval features for eval: 100%|██████████| 91/91 [04:25<00:00,  2.92s/it]\n",
      "2025-05-07 07:21:09,634 [INFO] Validation results: {'i_r1': 0.26846100759144237, 'i_r5': 0.538992408557626, 'i_r10': 0.6915113871635611, 'i_medr': 4.0, 'i_meanr': 13.071083505866115, 't_r1': 0.2401656314699793, 't_r5': 0.5327812284334024, 't_r10': 0.6853002070393375, 't_medr': 5.0, 't_meanr': 14.45824706694272}\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Student Hyperparameter Search 5th\n",
    "# Todo: Experiment with different hyperparameters in the random initialization setting (i.e. without finetuning). \n",
    "#       Try at least 3 new hyperparameter settings.\n",
    "#       Note the hyperparameters and the resulting image-to-text R@1 score in a table for each setting. \n",
    "#       Can you improve over the baselines? Add the table to your report. (1 point)\n",
    "train_retrieval_without_args(finetune=True, learning_rate=1e-2, weight_decay=1e-3, epochs=3, temperature=0.7, cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de0659-9b4b-4875-815a-b58a82cfc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize Top 10 results for a search query.\n",
    "\n",
    "from search_retrieval import get_top10\n",
    "\n",
    "search_query = \"a picture of a plane\"\n",
    "dict_top10 = get_top10(eval_ckpt=None, query = search_query)\n",
    "\n",
    "from PIL import Image\n",
    "for i in range(len(dict_top10[\"id\"])):\n",
    "    image_pil = Image.open(dict_top10[\"fname\"][i])\n",
    "    display(image_pil)\n",
    "    print(f\"Sim. Score: {dict_top10['sim'][i]}\")\n",
    "    print(f\"Caption: {dict_top10['caption'][i]}\")\n",
    "    #print(f\"Name: {dict_top10['name'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb8b9f-1e23-46cb-8784-13d8d8065b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
